{
  "cause": {
    "AllocatedCapacity": 40,
    "Arguments": {
      "--iceberg_warehouse": "s3://c108-prod-fpacfsa-final-zone/athenafarm/iceberg",
      "--full_load": "true",
      "--env": "PROD"
    },
    "Attempt": 0,
    "CompletedOn": 1772222144597,
    "ErrorMessage": "AnalysisException: Table or view not found: glue_catalog.sss.ibib;",
    "ExecutionTime": 35,
    "GlueVersion": "4.0",
    "Id": "jr_4ac6d0333ab54bb4a8c51fa3b55ad682da691c3a3e01816057212abea898a233",
    "JobMode": "SCRIPT",
    "JobName": "FSA-PROD-ATHENAFARM-Transform-Tract-Producer-Year",
    "JobRunState": "FAILED",
    "LastModifiedOn": 1772222144597,
    "LogGroupName": "/aws-glue/jobs",
    "MaxCapacity": 40,
    "NumberOfWorkers": 20,
    "PredecessorRuns": [],
    "StartedOn": 1772222102822,
    "Timeout": 480,
    "WorkerType": "G.2X"
  },
  "error": "States.TaskFailed",
  "resource": "startJobRun.sync",
  "resourceType": "glue"
}


6/02/27 19:55:50 ERROR ProcessLauncher: Exception in User Class
java.lang.reflect.UndeclaredThrowableException: null
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894) ~[hadoop-client-api-3.3.3-amzn-0.jar:?]
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:61) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:471) ~[spark-core_2.12-3.3.0-amzn-1.jar:?]
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:460) ~[spark-core_2.12-3.3.0-amzn-1.jar:?]
	at org.apache.spark.executor.CoarseGrainedExecutorBackendPlugin.launch(CoarseGrainedExecutorBackendWrapper.scala:10) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at org.apache.spark.executor.CoarseGrainedExecutorBackendPlugin.launch$(CoarseGrainedExecutorBackendWrapper.scala:10) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at org.apache.spark.executor.CoarseGrainedExecutorBackendWrapper$$anon$1.launch(CoarseGrainedExecutorBackendWrapper.scala:15) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at org.apache.spark.executor.CoarseGrainedExecutorBackendWrapper.launch(CoarseGrainedExecutorBackendWrapper.scala:19) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at org.apache.spark.executor.CoarseGrainedExecutorBackendWrapper$.main(CoarseGrainedExecutorBackendWrapper.scala:5) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at org.apache.spark.executor.CoarseGrainedExecutorBackendWrapper.main(CoarseGrainedExecutorBackendWrapper.scala) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_472]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_472]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_472]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_472]
	at com.amazonaws.services.glue.SparkProcessLauncherPlugin.invoke(ProcessLauncher.scala:68) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at com.amazonaws.services.glue.SparkProcessLauncherPlugin.invoke$(ProcessLauncher.scala:68) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at com.amazonaws.services.glue.ProcessLauncher$$anon$2.invoke(ProcessLauncher.scala:227) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at com.amazonaws.services.glue.ProcessLauncher.launch(ProcessLauncher.scala:493) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at com.amazonaws.services.glue.ProcessLauncher$.main(ProcessLauncher.scala:48) ~[AWSGlueSparkResourceManager-1.0.jar:?]
	at com.amazonaws.services.glue.ProcessLauncher.main(ProcessLauncher.scala) ~[AWSGlueSparkResourceManager-1.0.jar:?]
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.$anonfun$run$9(CoarseGrainedExecutorBackend.scala:491) ~[spark-core_2.12-3.3.0-amzn-1.jar:?]
	at scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23) ~[scala-library-2.12.15.jar:?]
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985) ~[scala-library-2.12.15.jar:?]
	at scala.collection.immutable.Range.foreach(Range.scala:158) ~[scala-library-2.12.15.jar:?]
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984) ~[scala-library-2.12.15.jar:?]
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.$anonfun$run$7(CoarseGrainedExecutorBackend.scala:489) ~[spark-core_2.12-3.3.0-amzn-1.jar:?]
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:62) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:61) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_472]
	at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_472]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-client-api-3.3.3-amzn-0.jar:?]
	... 19 more
Caused by: java.io.IOException: Failed to connect to /172.39.16.223:40937
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288) ~[spark-network-common_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218) ~[spark-network-common_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:230) ~[spark-network-common_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198) ~[spark-core_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_472]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_472]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_472]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_472]
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /172.39.16.223:40937
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_472]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716) ~[?:1.8.0_472]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330) ~[netty-transport-4.1.74.Final.jar:4.1.74.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334) ~[netty-transport-4.1.74.Final.jar:4.1.74.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:710) ~[netty-transport-4.1.74.Final.jar:4.1.74.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658) ~[netty-transport-4.1.74.Final.jar:4.1.74.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584) ~[netty-transport-4.1.74.Final.jar:4.1.74.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496) ~[netty-transport-4.1.74.Final.jar:4.1.74.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986) ~[netty-common-4.1.74.Final.jar:4.1.74.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.74.Final.jar:4.1.74.Final]
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.74.Final.jar:4.1.74.Final]
	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_472]

26/02/27 19:55:50 ERROR ProcessLauncher: Exception in User Class: java.lang.reflect.UndeclaredThrowableException
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1894)
org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:61)
org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:471)
org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:460)
org.apache.spark.executor.CoarseGrainedExecutorBackendPlugin.launch(CoarseGrainedExecutorBackendWrapper.scala:10)
org.apache.spark.executor.CoarseGrainedExecutorBackendPlugin.launch$(CoarseGrainedExecutorBackendWrapper.scala:10)
org.apache.spark.executor.CoarseGrainedExecutorBackendWrapper$$anon$1.launch(CoarseGrainedExecutorBackendWrapper.scala:15)
org.apache.spark.executor.CoarseGrainedExecutorBackendWrapper.launch(CoarseGrainedExecutorBackendWrapper.scala:19)
org.apache.spark.executor.CoarseGrainedExecutorBackendWrapper$.main(CoarseGrainedExecutorBackendWrapper.scala:5)
org.apache.spark.executor.CoarseGrainedExecutorBackendWrapper.main(CoarseGrainedExecutorBackendWrapper.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
com.amazonaws.services.glue.SparkProcessLauncherPlugin.invoke(ProcessLauncher.scala:68)
com.amazonaws.services.glue.SparkProcessLauncherPlugin.invoke$(ProcessLauncher.scala:68)
com.amazonaws.services.glue.ProcessLauncher$$anon$2.invoke(ProcessLauncher.scala:227)
com.amazonaws.services.glue.ProcessLauncher.launch(ProcessLauncher.scala:493)
com.amazonaws.services.glue.ProcessLauncher$.main(ProcessLauncher.scala:48)
com.amazonaws.services.glue.ProcessLauncher.main(ProcessLauncher.scala)


{
    "Event": "GlueETLJobExceptionEvent",
    "Timestamp": 1772222130459,
    "Failure Reason": "Traceback (most recent call last):\n  File \"/tmp/FSA-PROD-ATHENAFARM-Transform-Tract-Producer-Year.py\", line 140, in <module>\n    register_view(SSS_DB, tbl)\n  File \"/tmp/FSA-PROD-ATHENAFARM-Transform-Tract-Producer-Year.py\", line 134, in register_view\n    spark.table(fqn).createOrReplaceTempView(vn)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/session.py\", line 1055, in table\n    return DataFrame(self._jsparkSession.table(tableName), self)\n  File \"/opt/amazon/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1321, in __call__\n    return_value = get_return_value(\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 196, in deco\n    raise converted from None\npyspark.sql.utils.AnalysisException: Table or view not found: glue_catalog.sss.ibib;\n'UnresolvedRelation [glue_catalog, sss, ibib], [], false\n",
    "Stack Trace": [
        {
            "Declaring Class": "deco",
            "Method Name": "raise converted from None",
            "File Name": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/utils.py",
            "Line Number": 196
        },
        {
            "Declaring Class": "__call__",
            "Method Name": "return_value = get_return_value(",
            "File Name": "/opt/amazon/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py",
            "Line Number": 1321
        },
        {
            "Declaring Class": "table",
            "Method Name": "return DataFrame(self._jsparkSession.table(tableName), self)",
            "File Name": "/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/session.py",
            "Line Number": 1055
        },
        {
            "Declaring Class": "register_view",
            "Method Name": "spark.table(fqn).createOrReplaceTempView(vn)",
            "File Name": "/tmp/FSA-PROD-ATHENAFARM-Transform-Tract-Producer-Year.py",
            "Line Number": 134
        },
        {
            "Declaring Class": "<module>",
            "Method Name": "register_view(SSS_DB, tbl)",
            "File Name": "/tmp/FSA-PROD-ATHENAFARM-Transform-Tract-Producer-Year.py",
            "Line Number": 140
        }
    ],
    "Last Executed Line number": 140,
    "script": "FSA-PROD-ATHENAFARM-Transform-Tract-Producer-Year.py"
}
