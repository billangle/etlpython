# deploy/projects/cars/deploy.py
from __future__ import annotations

import importlib.util
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List
import sys

import boto3

from common.aws_common import (
    ensure_bucket_exists,
    ensure_lambda,
    ensure_glue_job,
    ensure_state_machine,
    LambdaSpec,
    GlueJobSpec,
    StateMachineSpec,
)



def _load_stepfunction_module():
    """
    Load ./states/cars_stepfunction.py by file path.
    IMPORTANT: register in sys.modules BEFORE exec_module so @dataclass works on Python 3.14.
    """
    project_dir = Path(__file__).resolve().parent  # .../deploy/projects/cars
    step_fn_file = project_dir / "states" / "cars_stepfunction.py"

    if not step_fn_file.exists():
        raise FileNotFoundError(f"Missing step function file: {step_fn_file}")

    module_name = "projects.cars.states.cars_stepfunction"
    spec = importlib.util.spec_from_file_location(module_name, str(step_fn_file))
    if spec is None or spec.loader is None:
        raise RuntimeError(f"Could not create module spec for: {step_fn_file}")

    mod = importlib.util.module_from_spec(spec)

    # âœ… Critical for Python 3.14 dataclasses: module must exist in sys.modules during execution
    sys.modules[module_name] = mod

    spec.loader.exec_module(mod)
    return mod



@dataclass(frozen=True)
class CarsEdvNames:
    build_processing_plan_fn: str
    check_results_fn: str
    finalize_pipeline_fn: str
    handle_failure_fn: str
    exec_sql_glue_job: str
    edv_state_machine: str
    download_zip_fn: str


def build_names(deploy_env: str) -> CarsEdvNames:
    """
    Naming matches your convention:
      - FSA-<ENV>-edv-*
      - FSA-<ENV>-DATAMART-EXEC-DB-SQL
      - FSA-<ENV>-DownloadZip
    """
    prefix = f"FSA-{deploy_env}"
    return CarsEdvNames(
        build_processing_plan_fn=f"{prefix}-edv-build-processing-plan",
        check_results_fn=f"{prefix}-edv-check-results",
        finalize_pipeline_fn=f"{prefix}-edv-finalize-pipeline",
        handle_failure_fn=f"{prefix}-edv-handle-failure",
        exec_sql_glue_job=f"{prefix}-DATAMART-EXEC-DB-SQL",
        edv_state_machine=f"{prefix}-CARS-EDV-Pipeline",
        download_zip_fn=f"{prefix}-DownloadZip",
    )


def _layers(cfg: Dict[str, Any]) -> List[str]:
    """
    Keep existing deploy.py behavior (optional two layers).
    """
    sp = cfg.get("strparams") or {}
    layers: List[str] = []
    for k in ("thirdPartyLayerArnParam", "customLayerArnParam"):
        v = sp.get(k)
        if v:
            layers.append(v)
    return layers


def deploy(cfg: Dict[str, Any], region: str) -> Dict[str, str]:
    """
    Deploys:
      - 5 Lambdas:
          cars/lambda/edv-build-processing-plan/lambda_function.py  (handler: lambda_function.handler)
          cars/lambda/edv-check-results/lambda_function.py          (handler: lambda_function.handler)
          cars/lambda/edv-finalize-pipeline/lambda_function.py      (handler: lambda_function.handler)
          cars/lambda/edv-handle-failure/lambda_function.py         (handler: lambda_function.handler)
          cars/lambda/DownloadZip/<your file>.py                    (handler: lambda_function.lambda_handler by default)
      - 1 Glue Job:
          cars/glue/FSA-CERT-DATAMART-EXEC-DB-SQL.py (uploaded to artifacts bucket)
      - 1 Step Function:
          definition generated by cars/states/cars_stepfunction.py (python builder)

    Required cfg keys (matches your existing deploy runner):
      cfg["deployEnv"]
      cfg["artifacts"]["artifactBucket"]
      cfg["artifacts"]["prefix"]
      cfg["strparams"]["etlRoleArnParam"]
      cfg["strparams"]["glueJobRoleArnParam"]
      cfg["stepFunctions"]["roleArn"]

    Optional:
      cfg["lambdaEnv"] (dict)
      cfg["glueDefaultArgs"] (dict)
      cfg["strparams"]["lambdaRuntime"] (defaults to python3.11)
      cfg["strparams"]["thirdPartyLayerArnParam"], cfg["strparams"]["customLayerArnParam"]
      cfg["downloadZip"]["handler"] (override handler string)
      cfg["downloadZip"]["sourceDirName"] (override folder name under cars/lambda/, default "DownloadZip")
    """
    deploy_env = cfg["deployEnv"]
    names = build_names(deploy_env)

    artifact_bucket = cfg["artifacts"]["artifactBucket"]
    prefix = cfg["artifacts"]["prefix"].rstrip("/") + "/"

    strparams = cfg.get("strparams") or {}
    etl_lambda_role_arn = strparams["etlRoleArnParam"]
    glue_job_role_arn = strparams["glueJobRoleArnParam"]

    sfn_role_arn = (cfg.get("stepFunctions") or {}).get("roleArn") or ""
    if not sfn_role_arn:
        raise RuntimeError("Missing required cfg.stepFunctions.roleArn")

    # Project assets (matches your folder layout)
    project_dir = Path(__file__).resolve().parent  # .../deploy/projects/cars
    lambda_root = project_dir / "lambda"
    glue_root = project_dir / "glue"

    # Lambda folders
    build_plan_dir = lambda_root / "edv-build-processing-plan"
    check_results_dir = lambda_root / "edv-check-results"
    finalize_dir = lambda_root / "edv-finalize-pipeline"
    handle_failure_dir = lambda_root / "edv-handle-failure"

    # DownloadZip folder + handler override (optional)
    dz_cfg = cfg.get("downloadZip") or {}
    download_zip_dirname = dz_cfg.get("sourceDirName", "DownloadZip")
    download_zip_dir = lambda_root / download_zip_dirname
    download_zip_handler = dz_cfg.get("handler", "lambda_function.lambda_handler")

    # Glue script (local)
    glue_script_local = glue_root / "FSA-CERT-DATAMART-EXEC-DB-SQL.py"

    # Clients
    session = boto3.Session(region_name=region)
    s3 = session.client("s3")
    lam = session.client("lambda")
    glue = session.client("glue")
    sfn = session.client("stepfunctions")

    ensure_bucket_exists(s3, artifact_bucket, region)

    # Optional env vars passed to all lambdas
    env_vars: Dict[str, str] = {}
    env_vars.update(cfg.get("lambdaEnv") or {})

    runtime = strparams.get("lambdaRuntime", "python3.11")
    layers = _layers(cfg)

    # --- Lambdas ---
    build_plan_arn = ensure_lambda(
        lam,
        LambdaSpec(
            name=names.build_processing_plan_fn,
            role_arn=etl_lambda_role_arn,
            handler="lambda_function.handler",
            runtime=runtime,
            source_dir=str(build_plan_dir),
            env=env_vars,
            layers=layers,
        ),
    )

    check_results_arn = ensure_lambda(
        lam,
        LambdaSpec(
            name=names.check_results_fn,
            role_arn=etl_lambda_role_arn,
            handler="lambda_function.handler",
            runtime=runtime,
            source_dir=str(check_results_dir),
            env=env_vars,
            layers=layers,
        ),
    )

    finalize_arn = ensure_lambda(
        lam,
        LambdaSpec(
            name=names.finalize_pipeline_fn,
            role_arn=etl_lambda_role_arn,
            handler="lambda_function.handler",
            runtime=runtime,
            source_dir=str(finalize_dir),
            env=env_vars,
            layers=layers,
        ),
    )

    handle_failure_arn = ensure_lambda(
        lam,
        LambdaSpec(
            name=names.handle_failure_fn,
            role_arn=etl_lambda_role_arn,
            handler="lambda_function.handler",
            runtime=runtime,
            source_dir=str(handle_failure_dir),
            env=env_vars,
            layers=layers,
        ),
    )

    download_zip_arn = ensure_lambda(
        lam,
        LambdaSpec(
            name=names.download_zip_fn,
            role_arn=etl_lambda_role_arn,
            handler=download_zip_handler,
            runtime=runtime,
            source_dir=str(download_zip_dir),
            env=env_vars,
            layers=layers,
        ),
    )

    # --- Glue job ---
    ensure_glue_job(
        glue,
        s3,
        GlueJobSpec(
            name=names.exec_sql_glue_job,
            role_arn=glue_job_role_arn,
            script_local_path=str(glue_script_local),
            script_s3_bucket=artifact_bucket,
            script_s3_key=f"{prefix}glue/{glue_script_local.name}",
            default_args=(cfg.get("glueDefaultArgs") or {}),
        ),
    )

    # --- Step Function (from python builder in states/cars_stepfunction.py) ---
    step_mod = _load_stepfunction_module()
    EdvPipelineStateMachineInputs = step_mod.EdvPipelineStateMachineInputs
    EdvPipelineStateMachineBuilder = step_mod.EdvPipelineStateMachineBuilder

    sm_inputs = EdvPipelineStateMachineInputs(
        build_processing_plan_fn=build_plan_arn,
        check_results_fn=check_results_arn,
        finalize_pipeline_fn=finalize_arn,
        handle_failure_fn=handle_failure_arn,
        exec_sql_glue_job_name=names.exec_sql_glue_job,
    )

    definition = EdvPipelineStateMachineBuilder.edv_pipeline_asl(sm_inputs)

    sfn_arn = ensure_state_machine(
        sfn,
        StateMachineSpec(
            name=names.edv_state_machine,
            role_arn=sfn_role_arn,
            definition=definition,
        ),
    )

    return {
        "lambda_build_processing_plan_arn": build_plan_arn,
        "lambda_check_results_arn": check_results_arn,
        "lambda_finalize_pipeline_arn": finalize_arn,
        "lambda_handle_failure_arn": handle_failure_arn,
        "lambda_download_zip_arn": download_zip_arn,
        "glue_job_name": names.exec_sql_glue_job,
        "state_machine_arn": sfn_arn,
    }
